{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuM-kMCuJpeP"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Tuple, Optional, Set, Dict\n",
        "import heapq\n",
        "# For Grid Representation\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Coord = Tuple[int, int]\n",
        "\n",
        "\n",
        "DYNAMIC_MOVE_PER_STEP = False   # how often cells move\n",
        "COVERAGE_FINAL_STATE  = False   # Measures how much the the drone explored\n",
        "\n",
        "# ----------GridWorld Class (The 2D Environment)----------\n",
        "\n",
        "@dataclass\n",
        "class GridWorld:\n",
        "  width: int\n",
        "  height: int\n",
        "  ObstacleRatio: float = 0.15 # percentage of cells randomly set as static objects\n",
        "  seed: int = 0\n",
        "  DynamicObstacles: int = 0 # Number of moving obstacles\n",
        "  DynamicMove_Prob: float = 0.2 # Probability that the object moves\n",
        "  grid: np.ndarray = field(init=False)\n",
        "  DynamicPositions: List[Coord] = field(default_factory=list) # List of Coordinates for dynamic obstacles\n",
        "  # Added: fixed final goal for all algorithms\n",
        "  Goal: Optional[Coord] = None\n",
        "\n",
        "  # Creating Random Static Obstacles\n",
        "  def __post_init__(self):\n",
        "    RNG = random.Random(self.seed)\n",
        "    self.grid = np.zeros((self.height, self.width), dtype=np.uint8)\n",
        "    # Static obstacles\n",
        "    NumberOf_Obstacles = int(self.width * self.height * self.ObstacleRatio)\n",
        "    placed = 0\n",
        "    while placed < NumberOf_Obstacles:\n",
        "      r, c = RNG.randrange(self.height), RNG.randrange(self.width)\n",
        "      if self.grid[r, c] == 0: # free\n",
        "        self.grid[r, c] = 1  # static obstacle\n",
        "        placed += 1\n",
        "\n",
        "    self.grid[0, 0] = 0 # Start cell is always free\n",
        "\n",
        "    # Dynamic obstacles\n",
        "    self.DynamicPositions = []\n",
        "    while len(self.DynamicPositions) < self.DynamicObstacles:\n",
        "      r, c = RNG.randrange(self.height), RNG.randrange(self.width)\n",
        "      if self.grid[r, c] == 0 and (r, c) not in self.DynamicPositions and (r, c) != (0,0):\n",
        "        self.DynamicPositions.append((r,c))\n",
        "\n",
        "    # Added: choose a fixed final goal (bottom-right), ensure it is free and not dynamic\n",
        "    if self.Goal is None:\n",
        "      self.Goal = (self.height - 1, self.width - 1)\n",
        "    gr, gc = self.Goal\n",
        "    self.grid[gr, gc] = 0\n",
        "    self.DynamicPositions = [p for p in self.DynamicPositions if p != self.Goal]\n",
        "\n",
        "\n",
        "  # --------Helper methods-------\n",
        "\n",
        "  # Check if Coordinate is inside the grid\n",
        "  def InBounds(self, p: Coord) -> bool:\n",
        "    r, c = p\n",
        "    return 0 <= r < self.height and 0 <= c < self.width\n",
        "\n",
        "  # Checks if a cell is not an obstacle (dynamic or otherwise)\n",
        "  def IsFree(self, p: Coord) -> bool:\n",
        "    r, c = p\n",
        "    if not self.InBounds(p):\n",
        "      return False\n",
        "    if self.grid[r, c] == 1:\n",
        "      return False\n",
        "    if p in self.DynamicPositions:\n",
        "      return False\n",
        "    return True\n",
        "\n",
        "  # Returns the 4-connected neighbours (up, down left, right)\n",
        "  def neighbors4(self, p: Coord) -> List[Coord]:\n",
        "    r, c = p\n",
        "    neighbor = [(r+1, c), (r-1, c), (r, c+1), (r, c-1)]\n",
        "    return [q for q in neighbor if self.InBounds(q)]\n",
        "\n",
        "  # Moves each dynamic obstacle randomly to an adjacent free cell with DynamicMove_Prob\n",
        "  def StepForDynamic(self, RNG: random.Random):\n",
        "    # FIX: prevent two obstacles taking the same new cell in the same tick\n",
        "    NewPositions = []\n",
        "    old = set(self.DynamicPositions)\n",
        "    taken = set()  # reserve new cells this tick\n",
        "    for position in self.DynamicPositions:\n",
        "        newpos = position\n",
        "        if RNG.random() < self.DynamicMove_Prob:\n",
        "            candidates = [q for q in self.neighbors4(position)\n",
        "                          if self.grid[q] == 0\n",
        "                          and q not in old        # not someoneâ€™s old spot\n",
        "                          and q not in taken      # not already taken this tick\n",
        "                          and q != (0, 0)         # don't sit on start\n",
        "                          and (self.Goal is None or q != self.Goal)]  # don't sit on goal\n",
        "            if candidates:\n",
        "                newpos = RNG.choice(candidates)\n",
        "        NewPositions.append(newpos)\n",
        "        taken.add(newpos)\n",
        "    self.DynamicPositions = NewPositions\n",
        "\n",
        "\n",
        "# --------- UAV Agent & Metrics -------------\n",
        "\n",
        "# Represents the UAV\n",
        "# Each move costs MoveCost Energy, and stops when BatteryCapacity is reached\n",
        "@dataclass\n",
        "class Agent:\n",
        "  start: Coord = (0, 0)\n",
        "  BatteryCapacity: int = 10_000 # Amount of \"Energy units\"\n",
        "  MoveCost: int = 1\n",
        "  path: List[Coord] = field(default_factory=lambda: [(0,0)])\n",
        "  EnergyUsed: int = 0\n",
        "# Returns the current positions\n",
        "  def at(self) -> Coord:\n",
        "    return self.path[-1]\n",
        "\n",
        "# Checks if the agent still has enegry\n",
        "  def CanMove(self) -> bool:\n",
        "    return (self.EnergyUsed + self.MoveCost) <= self.BatteryCapacity\n",
        "\n",
        "# Moves the UAV to the next cell, then updates the path and energy used\n",
        "  def MoveTo(self, p:Coord):\n",
        "    self.path.append(p)\n",
        "    self.EnergyUsed += self.MoveCost\n",
        "\n",
        "# Holds the performance data for a single simulation\n",
        "@dataclass\n",
        "class RunMetrics:\n",
        "  CoveragePercentage: float # CoveragePercentage\n",
        "  PathLength: int # Path Length\n",
        "  OverlapCount: int # Overlap Count\n",
        "  ExecutionTime: float # Execution Time\n",
        "  EnergyUsed: int # Energy Used\n",
        "  ReachedGoal: bool  # whether the goal was reached\n",
        "  TimeToGoal: Optional[float] = None # Time the goal was reached\n",
        "\n",
        "\n",
        "# ----------- Utilities -------------\n",
        "\n",
        "def manhattan(a: Coord, b: Coord) -> int:\n",
        "    return abs(a[0]-b[0]) + abs(a[1]-b[1])\n",
        "\n",
        "\n",
        "# Part of Astar search, it's job is to rebuild the path from the start cell to the goal cell (lists path from start cell to goal cell)\n",
        "def Rebuild_Path(From: Dict[Coord, Coord], goal: Coord) -> List[Coord]:\n",
        "    current = goal\n",
        "    rev = [current]\n",
        "    while current in From:\n",
        "        current = From[current]\n",
        "        rev.append(current)\n",
        "    rev.reverse()\n",
        "    return rev\n",
        "\n",
        "\n",
        "def Astar(grid: GridWorld, start: Coord, goal: Coord) -> Optional[List[Coord]]:\n",
        "    if not grid.IsFree(start) or not grid.IsFree(goal):\n",
        "        return None\n",
        "    openh = []\n",
        "    heapq.heappush(openh, (0 + manhattan(start, goal), 0, start))\n",
        "    From: Dict[Coord, Coord] = {}\n",
        "    g = {start: 0}\n",
        "    visited = set()\n",
        "    while openh:\n",
        "        f, cost, current = heapq.heappop(openh)\n",
        "        if current == goal:\n",
        "            return Rebuild_Path(From, current)\n",
        "        if current in visited:\n",
        "            continue\n",
        "        visited.add(current)\n",
        "        for nb in grid.neighbors4(current):\n",
        "            if not grid.IsFree(nb):\n",
        "                continue\n",
        "            newg = cost + 1\n",
        "            if nb not in g or newg < g[nb]:\n",
        "                g[nb] = newg\n",
        "                From[nb] = current\n",
        "                heapq.heappush(openh, (newg + manhattan(nb, goal), newg, nb))\n",
        "    return None\n",
        "\n",
        "\n",
        "# Helper to append a final A* leg to the fixed Goal\n",
        "# NOTE: also updates 'visited' and 'overlap' so Coverage/Overlap are correct during this final leg.\n",
        "def Append_Path_To_Goal(world: GridWorld, agent: Agent, RNG: random.Random, dynamic: bool,\n",
        "                        Max_steps: int, t0: float, steps: int,\n",
        "                        visited: Set[Coord],\n",
        "                        overlap: int,\n",
        "                        time_to_goal: Optional[float]) -> Tuple[int, int, Optional[float]]:\n",
        "    if world.Goal is None:\n",
        "        return steps, overlap, time_to_goal\n",
        "\n",
        "    while agent.CanMove() and steps < Max_steps:\n",
        "        if time.perf_counter() - t0 > 5.0:  # stop after 5 seconds\n",
        "            break\n",
        "        if dynamic and not DYNAMIC_MOVE_PER_STEP:\n",
        "            world.StepForDynamic(RNG)\n",
        "        cur = agent.at()\n",
        "        if cur == world.Goal:\n",
        "            if time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "            break\n",
        "        path = Astar(world, cur, world.Goal)\n",
        "        if path is None or len(path) <= 1:\n",
        "            break\n",
        "        # Follow step-by-step, re-checking dynamics\n",
        "        for nxt in path[1:]:\n",
        "            if dynamic and DYNAMIC_MOVE_PER_STEP:\n",
        "                world.StepForDynamic(RNG)\n",
        "            if dynamic and not world.IsFree(nxt):\n",
        "                break\n",
        "            if not agent.CanMove():\n",
        "                break\n",
        "            if nxt in visited:\n",
        "                overlap += 1\n",
        "            agent.MoveTo(nxt)\n",
        "            steps += 1\n",
        "            visited.add(nxt)\n",
        "            if agent.at() == world.Goal:\n",
        "                if time_to_goal is None:\n",
        "                    time_to_goal = time.perf_counter() - t0\n",
        "                break\n",
        "        if agent.at() == world.Goal:\n",
        "            break\n",
        "        # If dynamic blocked, loop will replan next iteration\n",
        "    return steps, overlap, time_to_goal\n",
        "\n",
        "\n",
        "# ----------------------- Algorithms -------------------------\n",
        "\n",
        "def Astar_Coverage(world: GridWorld, agent: Agent, seed: int = 0, dynamic: bool = False, Max_steps: int = 200_000) -> RunMetrics:\n",
        "    RNG = random.Random(seed)\n",
        "    visited = set([agent.at()]) # keeps track of all visited cells\n",
        "    overlap = 0 # counts revisited cells\n",
        "    t0 = time.perf_counter() # record start time\n",
        "    time_to_goal = None  # <-- track first reach time\n",
        "\n",
        "    # Builds a mask for all free celss\n",
        "    Free_Mask = np.zeros_like(world.grid, dtype=bool)\n",
        "    for r in range(world.height):\n",
        "        for c in range(world.width):\n",
        "            if world.grid[r, c] == 0:\n",
        "                Free_Mask[r, c] = True\n",
        "    Total_Free = int(Free_Mask.sum()) # Total number of free cells\n",
        "\n",
        "# Main loop: Keep looping until the agent still has battery, until the step count isn't exceeded and time doesn't run out\n",
        "    steps = 0\n",
        "    while agent.CanMove() and steps < Max_steps:\n",
        "        if time.perf_counter() - t0 > 5.0:  # stop after 5 seconds\n",
        "            break\n",
        "        if dynamic and not DYNAMIC_MOVE_PER_STEP:\n",
        "            world.StepForDynamic(RNG)\n",
        "\n",
        "      # Find nearest unvisited target\n",
        "        current = agent.at()\n",
        "        # Stop early if we already reached the fixed final goal\n",
        "        if world.Goal is not None and current == world.Goal:\n",
        "            if time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "            break\n",
        "\n",
        "        targets: List[Tuple[int, Coord]] = []\n",
        "        for r in range(world.height):\n",
        "            for c in range(world.width):\n",
        "                p = (r, c)\n",
        "                if Free_Mask[r, c] and p not in visited:\n",
        "                    targets.append((manhattan(current, p), p))\n",
        "        if not targets:\n",
        "            break\n",
        "        targets.sort(key=lambda x: x[0])\n",
        "\n",
        "        path = None\n",
        "        for _, goal in targets[:500]:  # try nearest few\n",
        "            path = Astar(world, current, goal)\n",
        "            if path:\n",
        "                break\n",
        "\n",
        "        if not path:  # no reachable unvisited cell (blocked by obstacles/dynamics)\n",
        "            break\n",
        "\n",
        "        # Follow the path step-by-step\n",
        "        for nxt in path[1:]:\n",
        "            if dynamic and DYNAMIC_MOVE_PER_STEP:\n",
        "                world.StepForDynamic(RNG)\n",
        "            if dynamic and not world.IsFree(nxt):\n",
        "                # Need to replan from current position\n",
        "                break\n",
        "            if not agent.CanMove():\n",
        "                break # out of battery\n",
        "            if nxt in visited:\n",
        "                overlap += 1\n",
        "            agent.MoveTo(nxt)\n",
        "            visited.add(nxt)\n",
        "            steps += 1\n",
        "            if world.Goal is not None and agent.at() == world.Goal and time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "                break\n",
        "\n",
        "    # Append a final leg to the common Goal for fair comparison\n",
        "    steps, overlap, time_to_goal = Append_Path_To_Goal(world, agent, RNG, dynamic, Max_steps, t0, steps, visited, overlap, time_to_goal)\n",
        "\n",
        "    t1 = time.perf_counter()\n",
        "    # Coverage definition (toggle final-state option)\n",
        "    if COVERAGE_FINAL_STATE:\n",
        "        Free_Mask_final = (world.grid == 0).copy()\n",
        "        for rr, cc in world.DynamicPositions:\n",
        "            Free_Mask_final[rr, cc] = False\n",
        "        Total_Free = int(Free_Mask_final.sum())\n",
        "    covered = len(visited)\n",
        "    CoveragePercentage = 100.0 * covered / max(1, Total_Free)\n",
        "    reached_goal = (world.Goal is not None and agent.at() == world.Goal)\n",
        "    return RunMetrics(\n",
        "        CoveragePercentage=CoveragePercentage,\n",
        "        PathLength=len(agent.path)-1,\n",
        "        OverlapCount=overlap,\n",
        "        ExecutionTime=t1 - t0,\n",
        "        EnergyUsed=agent.EnergyUsed,\n",
        "        ReachedGoal=reached_goal,\n",
        "        TimeToGoal=time_to_goal\n",
        "    )\n",
        "\n",
        "\n",
        "def RandomSweep(world: GridWorld, agent: Agent, seed: int = 0,\n",
        "                 dynamic: bool = False, Max_steps: int = 200_000) -> RunMetrics:\n",
        "    RNG = random.Random(seed)\n",
        "    visited = set([agent.at()])\n",
        "    overlap = 0\n",
        "    t0 = time.perf_counter()\n",
        "    time_to_goal = None  # <-- track first reach time\n",
        "\n",
        "    Free_Mask = (world.grid == 0)\n",
        "    Total_Free = int(Free_Mask.sum())\n",
        "\n",
        "    steps = 0\n",
        "    while agent.CanMove() and steps < Max_steps:\n",
        "        if time.perf_counter() - t0 > 5.0:  # stop after 5 seconds\n",
        "            break\n",
        "        if dynamic and not DYNAMIC_MOVE_PER_STEP:\n",
        "            world.StepForDynamic(RNG)\n",
        "        current = agent.at()\n",
        "        # Stop if at final goal\n",
        "        if world.Goal is not None and current == world.Goal:\n",
        "            if time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "            break\n",
        "        moves = [p for p in world.neighbors4(current) if world.IsFree(p)]\n",
        "        if not moves:\n",
        "            break\n",
        "        nxt = RNG.choice(moves)\n",
        "        if nxt in visited:\n",
        "            overlap += 1\n",
        "        agent.MoveTo(nxt)\n",
        "        visited.add(nxt)\n",
        "        steps += 1\n",
        "        if dynamic and DYNAMIC_MOVE_PER_STEP:\n",
        "            world.StepForDynamic(RNG)\n",
        "        if world.Goal is not None and agent.at() == world.Goal and time_to_goal is None:\n",
        "            time_to_goal = time.perf_counter() - t0\n",
        "            break\n",
        "        if len(visited) >= Total_Free:\n",
        "            break\n",
        "\n",
        "    # Append a final leg to the common Goal\n",
        "    steps, overlap, time_to_goal = Append_Path_To_Goal(world, agent, RNG, dynamic, Max_steps, t0, steps, visited, overlap, time_to_goal)\n",
        "\n",
        "    t1 = time.perf_counter()\n",
        "    # Coverage definition (toggle final-state option)\n",
        "    if COVERAGE_FINAL_STATE:\n",
        "        Free_Mask_final = (world.grid == 0).copy()\n",
        "        for rr, cc in world.DynamicPositions:\n",
        "            Free_Mask_final[rr, cc] = False\n",
        "        Total_Free = int(Free_Mask_final.sum())\n",
        "    CoveragePercentage = 100.0 * len(visited) / max(1, Total_Free)\n",
        "    reached_goal = (world.Goal is not None and agent.at() == world.Goal)\n",
        "    return RunMetrics(\n",
        "        CoveragePercentage=CoveragePercentage,\n",
        "        PathLength=len(agent.path)-1,\n",
        "        OverlapCount=overlap,\n",
        "        ExecutionTime=t1 - t0,\n",
        "        EnergyUsed=agent.EnergyUsed,\n",
        "        ReachedGoal=reached_goal,\n",
        "        TimeToGoal=time_to_goal\n",
        "    )\n",
        "\n",
        "\n",
        "# Simulated Annealing\n",
        "\n",
        "def SimulatedAnnealing(world: GridWorld, agent: Agent, seed: int = 0, dynamic: bool = False, Max_steps: int = 200_000) -> RunMetrics:\n",
        "    RNG = random.Random(seed)\n",
        "    visited = set([agent.at()])  # set of already visited cells\n",
        "    overlap = 0                  # counts how many times agent revisits a cell\n",
        "    t0 = time.perf_counter()     # measuring execution time\n",
        "    time_to_goal = None          # <-- track first reach time\n",
        "\n",
        "    # Build a mask of free cells\n",
        "    Free_Mask = np.zeros_like(world.grid, dtype=bool)\n",
        "    for r in range(world.height):\n",
        "        for c in range(world.width):\n",
        "            if world.grid[r, c] == 0:\n",
        "                Free_Mask[r, c] = True\n",
        "    Total_Free = int(Free_Mask.sum())\n",
        "\n",
        "    steps = 0\n",
        "    T0, T_min, cooling = 5.0, 0.1, 0.995  # temperature parameters\n",
        "    T = T0\n",
        "\n",
        "    while agent.CanMove() and steps < Max_steps:  # loop until energy runs out or time expires\n",
        "        if time.perf_counter() - t0 > 5.0:\n",
        "            break\n",
        "        if dynamic and not DYNAMIC_MOVE_PER_STEP:\n",
        "            world.StepForDynamic(RNG)\n",
        "\n",
        "        current = agent.at()\n",
        "        # Stop if at final goal\n",
        "        if world.Goal is not None and current == world.Goal:\n",
        "            if time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "            break\n",
        "\n",
        "        # gather candidate unvisited frontiers (nearest first)\n",
        "        candidates: List[Tuple[int, Coord]] = []\n",
        "        for r in range(world.height):\n",
        "            for c in range(world.width):\n",
        "                p = (r, c)\n",
        "                if Free_Mask[r, c] and p not in visited:\n",
        "                    candidates.append((abs(r-current[0]) + abs(c-current[1]), p))\n",
        "\n",
        "        if not candidates:\n",
        "            break\n",
        "        candidates.sort(key=lambda x: x[0])\n",
        "        candidates = candidates[:200]  # limit scope\n",
        "\n",
        "        # SA choice: softmin over distance with temperature\n",
        "        dists = [max(1, d) for d, _ in candidates]\n",
        "        weights = [math.exp(-d / max(T, 1e-6)) for d in dists]  # Boltzmann\n",
        "        s = sum(weights)\n",
        "        probs = [w / s for w in weights]\n",
        "\n",
        "        # Sample one goal according to those probabilities\n",
        "        rnum = RNG.random()\n",
        "        cum = 0.0\n",
        "        goal = candidates[0][1]\n",
        "        for (d, p), pr in zip(candidates, probs):\n",
        "            cum += pr\n",
        "            if rnum <= cum:\n",
        "                goal = p\n",
        "                break\n",
        "\n",
        "        # Use A* to traverse to the goal; if fails, try a few alternates\n",
        "        path = Astar(world, current, goal)\n",
        "        tries = 0\n",
        "        while path is None and tries < 10 and candidates:\n",
        "            goal = candidates[min(len(candidates)-1, RNG.randrange(len(candidates)))][1]\n",
        "            path = Astar(world, current, goal)\n",
        "            tries += 1\n",
        "        if path is None:\n",
        "            break\n",
        "\n",
        "        # Path following\n",
        "        for nxt in path[1:]:\n",
        "            if dynamic and DYNAMIC_MOVE_PER_STEP:\n",
        "                world.StepForDynamic(RNG)\n",
        "            if dynamic and not world.IsFree(nxt):\n",
        "                break\n",
        "            if not agent.CanMove():\n",
        "                break\n",
        "            if nxt in visited:\n",
        "                overlap += 1\n",
        "            agent.MoveTo(nxt)\n",
        "            visited.add(nxt)\n",
        "            steps += 1\n",
        "            if world.Goal is not None and agent.at() == world.Goal and time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "                break\n",
        "\n",
        "        T = max(T_min, T * cooling)  # cool down\n",
        "\n",
        "    # Append a final leg to the common Goal\n",
        "    steps, overlap, time_to_goal = Append_Path_To_Goal(\n",
        "        world, agent, RNG, dynamic, Max_steps, t0, steps, visited, overlap, time_to_goal\n",
        "    )\n",
        "\n",
        "    # Returning Performance metrics\n",
        "    t1 = time.perf_counter()\n",
        "    if COVERAGE_FINAL_STATE:\n",
        "        Free_Mask_final = (world.grid == 0).copy()\n",
        "        for rr, cc in world.DynamicPositions:\n",
        "            Free_Mask_final[rr, cc] = False\n",
        "        Total_Free = int(Free_Mask_final.sum())\n",
        "    CoveragePercentage = 100.0 * len(visited) / max(1, Total_Free)\n",
        "    reached_goal = (world.Goal is not None and agent.at() == world.Goal)\n",
        "    return RunMetrics(CoveragePercentage, len(agent.path)-1, overlap, t1 - t0, agent.EnergyUsed, ReachedGoal=reached_goal, TimeToGoal=time_to_goal)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Ant Colony Optimization\n",
        "\n",
        "def AntColony(world: GridWorld, agent: Agent, seed: int = 0, dynamic: bool = False, Max_steps: int = 200_000) -> RunMetrics:\n",
        "\n",
        "  # Tracks visited cells, overlap count, and a start timer\n",
        "    RNG = random.Random(seed)\n",
        "    visited = set([agent.at()])\n",
        "    overlap = 0\n",
        "    t0 = time.perf_counter()\n",
        "    time_to_goal = None  # <-- track first reach time\n",
        "\n",
        "# Computes which cells are free\n",
        "    Free_Mask = np.zeros_like(world.grid, dtype=bool)\n",
        "    for r in range(world.height):\n",
        "        for c in range(world.width):\n",
        "            if world.grid[r, c] == 0:\n",
        "                Free_Mask[r, c] = True\n",
        "    Total_Free = int(Free_Mask.sum())\n",
        "\n",
        "    pher = np.full_like(world.grid, 1.0, dtype=float)\n",
        "    rho = 0.02     # evaporation\n",
        "    alpha = 1.0    # pheromone weight\n",
        "    beta = 2.0     # heuristic (1/distance) weight\n",
        "    reward = 5.0   # deposit for newly covered cells\n",
        "\n",
        "# Run until battery, step cap, or 5 second time limit is exceeded\n",
        "    steps = 0\n",
        "    while agent.CanMove() and steps < Max_steps:\n",
        "        if time.perf_counter() - t0 > 5.0:\n",
        "            break\n",
        "        if dynamic and not DYNAMIC_MOVE_PER_STEP:\n",
        "            world.StepForDynamic(RNG)\n",
        "\n",
        "        current = agent.at()\n",
        "        # Stop if at final goal\n",
        "        if world.Goal is not None and current == world.Goal:\n",
        "            if time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "            break\n",
        "\n",
        "        # building candidate frontiers\n",
        "        cand: List[Tuple[int, Coord]] = []\n",
        "        for r in range(world.height):\n",
        "            for c in range(world.width):\n",
        "                p = (r, c)\n",
        "                if Free_Mask[r, c] and p not in visited:\n",
        "                    cand.append((abs(r-current[0]) + abs(c-current[1]), p))\n",
        "        if not cand:\n",
        "            break\n",
        "        cand.sort(key=lambda x: x[0])\n",
        "        cand = cand[:200]\n",
        "        numer = []\n",
        "        for d, p in cand:\n",
        "            d = max(1, d)\n",
        "            tau = pher[p]\n",
        "            eta = 1.0 / d\n",
        "            numer.append((tau ** alpha) * (eta ** beta))\n",
        "        s = sum(numer)\n",
        "\n",
        "        # If all scores are zero pick the nearest, otherwise sample a goal proportional to its hueristic score\n",
        "        if s == 0:\n",
        "            goal = cand[0][1]\n",
        "        else:\n",
        "            rnum = RNG.random()\n",
        "            cum = 0.0\n",
        "            goal = cand[0][1]\n",
        "            for (d, p), val in zip(cand, numer):\n",
        "                cum += val / s\n",
        "                if rnum <= cum:\n",
        "                    goal = p\n",
        "                    break\n",
        "\n",
        "# Return to the chosen goal using Astar\n",
        "        path = Astar(world, current, goal)\n",
        "        tries = 0\n",
        "        while path is None and tries < 10 and cand:\n",
        "            # pick another candidate if current is unreachable\n",
        "            goal = cand[min(len(cand)-1, RNG.randrange(len(cand)))][1] if cand else goal\n",
        "            path = Astar(world, current, goal)\n",
        "            tries += 1\n",
        "        if path is None:\n",
        "            # evaporate and continue\n",
        "            pher *= (1.0 - rho)\n",
        "            continue\n",
        "\n",
        "# Execute the path & count new average\n",
        "        newly = 0\n",
        "        for nxt in path[1:]:\n",
        "            if dynamic and DYNAMIC_MOVE_PER_STEP:\n",
        "                world.StepForDynamic(RNG)\n",
        "            if dynamic and not world.IsFree(nxt):\n",
        "                break\n",
        "            if not agent.CanMove():\n",
        "                break\n",
        "            if nxt in visited:\n",
        "                overlap += 1\n",
        "            else:\n",
        "                newly += 1\n",
        "            agent.MoveTo(nxt)\n",
        "            visited.add(nxt)\n",
        "            steps += 1\n",
        "            if world.Goal is not None and agent.at() == world.Goal and time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "                break\n",
        "\n",
        "        # pheromone update\n",
        "        pher *= (1.0 - rho)\n",
        "        if newly > 0:\n",
        "            pher[goal] += reward * newly\n",
        "\n",
        "    # Append a final leg to the common Goal\n",
        "    steps, overlap, time_to_goal = Append_Path_To_Goal(world, agent, RNG, dynamic, Max_steps, t0, steps, visited, overlap, time_to_goal)\n",
        "\n",
        "# Computing final metrics\n",
        "    t1 = time.perf_counter()\n",
        "    if COVERAGE_FINAL_STATE:\n",
        "        Free_Mask_final = (world.grid == 0).copy()\n",
        "        for rr, cc in world.DynamicPositions:\n",
        "            Free_Mask_final[rr, cc] = False\n",
        "        Total_Free = int(Free_Mask_final.sum())\n",
        "    CoveragePercentage = 100.0 * len(visited) / max(1, Total_Free)\n",
        "    reached_goal = (world.Goal is not None and agent.at() == world.Goal)\n",
        "    return RunMetrics(CoveragePercentage, len(agent.path)-1, overlap, t1 - t0, agent.EnergyUsed, ReachedGoal=reached_goal, TimeToGoal=time_to_goal)\n",
        "\n",
        "\n",
        "# Genetic Algorithm\n",
        "\n",
        "def GeneticAlgorithm(world: GridWorld, agent: Agent, seed: int = 0, dynamic: bool = False, Max_steps: int = 200_000) -> RunMetrics:\n",
        "\n",
        "  # Setup\n",
        "    RNG = random.Random(seed)\n",
        "    visited = set([agent.at()])\n",
        "    overlap = 0\n",
        "    t0 = time.perf_counter()\n",
        "    time_to_goal = None  # <-- track first reach time\n",
        "\n",
        "# Marks all free cells\n",
        "    Free_Mask = np.zeros_like(world.grid, dtype=bool)\n",
        "    for r in range(world.height):\n",
        "        for c in range(world.width):\n",
        "            if world.grid[r, c] == 0:\n",
        "                Free_Mask[r, c] = True\n",
        "    Total_Free = int(Free_Mask.sum())\n",
        "\n",
        "# Finds unvisited free cells\n",
        "    def frontier_list(cur: Coord) -> List[Coord]:\n",
        "        L: List[Tuple[int, Coord]] = []\n",
        "        for r in range(world.height):\n",
        "            for c in range(world.width):\n",
        "                p = (r, c)\n",
        "                if Free_Mask[r, c] and p not in visited:\n",
        "                    L.append((abs(r-cur[0]) + abs(c-cur[1]), p))\n",
        "        L.sort(key=lambda x: x[0])\n",
        "        return [p for _, p in L[:300]]\n",
        "\n",
        "   # GA Parameters\n",
        "    pop_size = 20\n",
        "    seq_len = 5\n",
        "    cx_rate = 0.7\n",
        "    mut_rate = 0.3\n",
        "    gens = 12\n",
        "\n",
        "# UAV moves until its of energy, times out (5s) or step count is reached\n",
        "    steps = 0\n",
        "    while agent.CanMove() and steps < Max_steps:\n",
        "        if time.perf_counter() - t0 > 5.0:\n",
        "            break\n",
        "        if dynamic and not DYNAMIC_MOVE_PER_STEP:\n",
        "            world.StepForDynamic(RNG)\n",
        "\n",
        "        cur = agent.at()\n",
        "        # Stop if at final goal\n",
        "        if world.Goal is not None and cur == world.Goal:\n",
        "            if time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "            break\n",
        "\n",
        "        fr = frontier_list(cur)\n",
        "        if not fr:\n",
        "            break\n",
        "\n",
        "# creates a random sequence of 5 candidate goals\n",
        "        def random_seq():\n",
        "            return [fr[RNG.randrange(len(fr))] for _ in range(seq_len)]\n",
        "\n",
        "# For each sequence it uses Astar to estimate the path length to each goal\n",
        "        def fitness(seq: List[Coord]) -> float:\n",
        "            pos = cur\n",
        "            length = 0\n",
        "            gain = 0\n",
        "            for g in seq:\n",
        "                path = Astar(world, pos, g)\n",
        "                if path is None:\n",
        "                    length += 1_000_000\n",
        "                    continue\n",
        "                length += len(path) - 1\n",
        "                # estimate newly visited reward (heuristic)\n",
        "                gain += 1.0 if g not in visited else 0.0\n",
        "                pos = g\n",
        "            # lower length and higher gain is better\n",
        "            return length - 50.0 * gain\n",
        "\n",
        "# GA evolution\n",
        "        pop = [random_seq() for _ in range(pop_size)]\n",
        "        for _ in range(gens):\n",
        "            scores = [(fitness(ind), ind) for ind in pop]\n",
        "            scores.sort(key=lambda x: x[0])\n",
        "            elite = [ind for _, ind in scores[:max(2, pop_size // 5)]]\n",
        "            new_pop = elite[:]\n",
        "            while len(new_pop) < pop_size:\n",
        "                if RNG.random() < cx_rate:\n",
        "                    a = RNG.choice(elite)\n",
        "                    b = RNG.choice(pop)\n",
        "                    cut = RNG.randrange(1, seq_len)\n",
        "                    child = a[:cut] + b[cut:]\n",
        "                else:\n",
        "                    child = RNG.choice(pop)[:]\n",
        "                if RNG.random() < mut_rate:\n",
        "                    idx = RNG.randrange(seq_len)\n",
        "                    child[idx] = fr[RNG.randrange(len(fr))]\n",
        "                new_pop.append(child)\n",
        "            pop = new_pop\n",
        "\n",
        "        # takes the best and execute its first waypoint\n",
        "        best_seq = min(pop, key=fitness)\n",
        "        goal = best_seq[0]\n",
        "        path = Astar(world, cur, goal)\n",
        "        if path is None:\n",
        "            continue\n",
        "\n",
        "       # Move UAV along the path\n",
        "        for nxt in path[1:]:\n",
        "            if dynamic and DYNAMIC_MOVE_PER_STEP:\n",
        "                world.StepForDynamic(RNG)\n",
        "            if dynamic and not world.IsFree(nxt):\n",
        "                break\n",
        "            if not agent.CanMove():\n",
        "                break\n",
        "            if nxt in visited:\n",
        "                overlap += 1\n",
        "            agent.MoveTo(nxt)\n",
        "            visited.add(nxt)\n",
        "            steps += 1\n",
        "            if world.Goal is not None and agent.at() == world.Goal and time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "                break\n",
        "\n",
        "    # Append a final leg to the common Goal\n",
        "    steps, overlap, time_to_goal = Append_Path_To_Goal(world, agent, RNG, dynamic, Max_steps, t0, steps, visited, overlap, time_to_goal)\n",
        "\n",
        "# Return Metrics\n",
        "    t1 = time.perf_counter()\n",
        "    if COVERAGE_FINAL_STATE:\n",
        "        Free_Mask_final = (world.grid == 0).copy()\n",
        "        for rr, cc in world.DynamicPositions:\n",
        "            Free_Mask_final[rr, cc] = False\n",
        "        Total_Free = int(Free_Mask_final.sum())\n",
        "    CoveragePercentage = 100.0 * len(visited) / max(1, Total_Free)\n",
        "    reached_goal = (world.Goal is not None and agent.at() == world.Goal)\n",
        "    return RunMetrics(CoveragePercentage, len(agent.path)-1, overlap, t1 - t0, agent.EnergyUsed, ReachedGoal=reached_goal, TimeToGoal=time_to_goal)\n",
        "\n",
        "\n",
        "# Particle Swarm Optimisation\n",
        "\n",
        "def PSO(world: GridWorld, agent: Agent, seed: int = 0, dynamic: bool = False, Max_steps: int = 200_000) -> RunMetrics:\n",
        "\n",
        "  # Setup\n",
        "    RNG = random.Random(seed)\n",
        "    visited = set([agent.at()])\n",
        "    overlap = 0\n",
        "    t0 = time.perf_counter()\n",
        "    time_to_goal = None  # <-- track first reach time\n",
        "\n",
        "# Marks static free cells\n",
        "    Free_Mask = np.zeros_like(world.grid, dtype=bool)\n",
        "    for r in range(world.height):\n",
        "        for c in range(world.width):\n",
        "            if world.grid[r, c] == 0:\n",
        "                Free_Mask[r, c] = True\n",
        "    Total_Free = int(Free_Mask.sum())\n",
        "\n",
        "# Builds list of of unvisted free cells\n",
        "    def frontier(cur: Coord) -> List[Coord]:\n",
        "        L: List[Tuple[int, Coord]] = []\n",
        "        for r in range(world.height):\n",
        "            for c in range(world.width):\n",
        "                p = (r, c)\n",
        "                if Free_Mask[r, c] and p not in visited:\n",
        "                    L.append((abs(r-cur[0]) + abs(c-cur[1]), p))\n",
        "        L.sort(key=lambda x: x[0])\n",
        "        return [p for _, p in L[:300]]\n",
        "\n",
        "# Fitness function: If unreachable it gets a penalty, bonus for being in a locally unvisited neighbourhood\n",
        "    def fitness(cur: Coord, goal: Coord) -> float:\n",
        "        path = Astar(world, cur, goal)\n",
        "        if path is None:\n",
        "            return 1e9\n",
        "        # prefer shorter route and goals in less-visited areas\n",
        "        r, c = goal\n",
        "        unv = 0\n",
        "        for rr in range(max(0, r-1), min(world.height, r+2)):\n",
        "            for cc in range(max(0, c-1), min(world.width, c+2)):\n",
        "                if Free_Mask[rr, cc] and (rr, cc) not in visited:\n",
        "                    unv += 1\n",
        "        return (len(path) - 1) - 3.0 * unv\n",
        "\n",
        "# Stops when out of energy, over the step cap, or past the 5 second limit\n",
        "    steps = 0\n",
        "    while agent.CanMove() and steps < Max_steps:\n",
        "        if time.perf_counter() - t0 > 5.0:\n",
        "            break\n",
        "        if dynamic and not DYNAMIC_MOVE_PER_STEP:\n",
        "            world.StepForDynamic(RNG)\n",
        "\n",
        "# Initialise the Swarm\n",
        "        cur = agent.at()\n",
        "        # Stop if at final goal\n",
        "        if world.Goal is not None and cur == world.Goal:\n",
        "            if time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "            break\n",
        "\n",
        "        F = frontier(cur)\n",
        "        if not F:\n",
        "            break\n",
        "        swarm_size = min(25, max(5, len(F)//8))\n",
        "        particles = [F[RNG.randrange(len(F))] for _ in range(swarm_size)]\n",
        "        pbest = particles[:]\n",
        "        pbest_fit = [fitness(cur, g) for g in pbest]\n",
        "        gbest_idx = min(range(swarm_size), key=lambda i: pbest_fit[i])\n",
        "        gbest = pbest[gbest_idx]\n",
        "\n",
        "# After moving each particle, recompute fitness and update the personal best\n",
        "        iters = 10\n",
        "        for _ in range(iters):\n",
        "            for i in range(swarm_size):\n",
        "                # \"velocity\" proxy: jitter toward gbest by choosing a nearby frontier\n",
        "                if RNG.random() < 0.6:\n",
        "                    # pick among K nearest to gbest\n",
        "                    gr, gc = gbest\n",
        "                    neighs = sorted(F, key=lambda p: abs(p[0]-gr) + abs(p[1]-gc))[:20]\n",
        "                    particles[i] = RNG.choice(neighs)\n",
        "                else:\n",
        "                    particles[i] = F[RNG.randrange(len(F))]\n",
        "                fit = fitness(cur, particles[i])\n",
        "                if fit < pbest_fit[i]:\n",
        "                    pbest[i] = particles[i]\n",
        "                    pbest_fit[i] = fit\n",
        "            gbest_idx = min(range(swarm_size), key=lambda j: pbest_fit[j])\n",
        "            gbest = pbest[gbest_idx]\n",
        "\n",
        "# Execute the best found goal using Astar\n",
        "        goal = gbest\n",
        "        path = Astar(world, cur, goal)\n",
        "        if path is None:\n",
        "            continue\n",
        "        for nxt in path[1:]:\n",
        "            if dynamic and DYNAMIC_MOVE_PER_STEP:\n",
        "                world.StepForDynamic(RNG)\n",
        "            if dynamic and not world.IsFree(nxt):\n",
        "                break\n",
        "            if not agent.CanMove():\n",
        "                break\n",
        "            if nxt in visited:\n",
        "                overlap += 1\n",
        "            agent.MoveTo(nxt)\n",
        "            visited.add(nxt)\n",
        "            steps += 1\n",
        "            if world.Goal is not None and agent.at() == world.Goal and time_to_goal is None:\n",
        "                time_to_goal = time.perf_counter() - t0\n",
        "                break\n",
        "\n",
        "    # Append a final leg to the common Goal\n",
        "    steps, overlap, time_to_goal = Append_Path_To_Goal(world, agent, RNG, dynamic, Max_steps, t0, steps, visited, overlap, time_to_goal)\n",
        "\n",
        "# Computing metrics\n",
        "    t1 = time.perf_counter()\n",
        "    if COVERAGE_FINAL_STATE:\n",
        "        Free_Mask_final = (world.grid == 0).copy()\n",
        "        for rr, cc in world.DynamicPositions:\n",
        "            Free_Mask_final[rr, cc] = False\n",
        "        Total_Free = int(Free_Mask_final.sum())\n",
        "    CoveragePercentage = 100.0 * len(visited) / max(1, Total_Free)\n",
        "    reached_goal = (world.Goal is not None and agent.at() == world.Goal)\n",
        "    return RunMetrics(CoveragePercentage, len(agent.path)-1, overlap, t1 - t0, agent.EnergyUsed, ReachedGoal=reached_goal, TimeToGoal=time_to_goal)\n",
        "\n",
        "\n",
        "# ---------------- Path optimizers ----------------\n",
        "\n",
        "# -------- Tabu Search path improver --------\n",
        "def tabu_improve_path(world: GridWorld,\n",
        "                      path: List[Coord],\n",
        "                      time_limit: float = 0.75,\n",
        "                      max_iters: int = 2000,\n",
        "                      tabu_tenure: int = 25,\n",
        "                      seed: int = 0) -> Tuple[List[Coord], Dict[str, int]]:\n",
        "\n",
        "    RNG = random.Random(seed)\n",
        "\n",
        "    # Quick guards\n",
        "    if len(path) < 3:\n",
        "        return path[:], {\"iters\": 0, \"accepted\": 0, \"best_len\": max(0, len(path)-1)}\n",
        "\n",
        "    def path_len(pth: List[Coord]) -> int:\n",
        "        return max(0, len(pth) - 1)\n",
        "\n",
        "    def valid_consecutive(a: Coord, b: Coord) -> bool:\n",
        "        # 4-connected neighbors\n",
        "        return abs(a[0]-b[0]) + abs(a[1]-b[1]) == 1\n",
        "\n",
        "    def feasible(pth: List[Coord]) -> bool:\n",
        "        # cells must be free (given world's final state) & steps 4-connected\n",
        "        for q in pth:\n",
        "            if not world.IsFree(q):\n",
        "                return False\n",
        "        for u, v in zip(pth, pth[1:]):\n",
        "            if not valid_consecutive(u, v):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    # Build a canonical edge representation\n",
        "    def edge(u: Coord, v: Coord) -> Tuple[Coord, Coord]:\n",
        "        return (u, v)\n",
        "\n",
        "    # Shortcut move: reconnect path[i] -> path[j] using A*\n",
        "    def try_shortcut(cur_path: List[Coord], i: int, j: int) -> Optional[List[Coord]]:\n",
        "        if j <= i + 1:  # nothing to shortcut\n",
        "            return None\n",
        "        a, b = cur_path[i], cur_path[j]\n",
        "        new_leg = Astar(world, a, b)\n",
        "        if not new_leg or len(new_leg) < 2:\n",
        "            return None\n",
        "        # splice: [..i] + new_leg[1:] + [j+1..]\n",
        "        cand = cur_path[:i+1] + new_leg[1:] + cur_path[j+1:]\n",
        "        return cand if feasible(cand) else None\n",
        "\n",
        "    # Relocate/skip waypoint k: reconnect k-1 -> k+1 via A*\n",
        "    def try_skip(cur_path: List[Coord], k: int) -> Optional[List[Coord]]:\n",
        "        if k <= 0 or k >= len(cur_path) - 1:\n",
        "            return None\n",
        "        a, b = cur_path[k-1], cur_path[k+1]\n",
        "        new_leg = Astar(world, a, b)\n",
        "        if not new_leg or len(new_leg) < 2:\n",
        "            return None\n",
        "        cand = cur_path[:k] + new_leg[1:] + cur_path[k+1:]\n",
        "        return cand if feasible(cand) else None\n",
        "\n",
        "    best = path[:]\n",
        "    best_val = path_len(best)\n",
        "    cur = best[:]\n",
        "    cur_val = best_val\n",
        "\n",
        "    # Tabu list: recently removed edges with remaining tenure\n",
        "    tabu: Dict[Tuple[Coord, Coord], int] = {}\n",
        "    accepted = 0\n",
        "    t_start = time.perf_counter()\n",
        "\n",
        "    it = 0\n",
        "    while it < max_iters and (time.perf_counter() - t_start) < time_limit:\n",
        "        it += 1\n",
        "\n",
        "        n = len(cur)\n",
        "        if n < 3:\n",
        "            # Nothing more to improve safely\n",
        "            break\n",
        "\n",
        "        # Decay tabu tenures (safe iteration)\n",
        "        if tabu:\n",
        "            to_del = []\n",
        "            for e in list(tabu.keys()):\n",
        "                tabu[e] -= 1\n",
        "                if tabu[e] <= 0:\n",
        "                    to_del.append(e)\n",
        "            for e in to_del:\n",
        "                del tabu[e]\n",
        "\n",
        "        candidates = []\n",
        "\n",
        "        # --- Shortcuts: generate only valid (i, j) with i+2 <= j < n\n",
        "        if n >= 3:\n",
        "            for _ in range(16):\n",
        "                # pick i in [0, n-3] so i+2 <= n-1 exists\n",
        "                i = RNG.randrange(0, n - 2)\n",
        "                # bias to local windows but ensure a valid range\n",
        "                if RNG.random() < 0.6:\n",
        "                    j_min = i + 2\n",
        "                    j_max = min(n - 1, i + 2 + RNG.randrange(6))\n",
        "                    if j_min >= n:\n",
        "                        continue\n",
        "                    if j_max < j_min:\n",
        "                        j_max = j_min\n",
        "                    j = j_min if j_max == j_min else RNG.randrange(j_min, j_max + 1)\n",
        "                else:\n",
        "                    j_min = i + 2\n",
        "                    if j_min >= n:\n",
        "                        continue\n",
        "                    j = RNG.randrange(j_min, n)\n",
        "                cand = try_shortcut(cur, i, j)\n",
        "                if cand:\n",
        "                    removed = edge(cur[i], cur[i+1])\n",
        "                    candidates.append((\"shortcut\", i, j, cand, removed))\n",
        "\n",
        "        # --- Skips (only if there is an interior k)\n",
        "        if n > 3:\n",
        "            for _ in range(12):\n",
        "                k = RNG.randrange(1, n - 1)\n",
        "                cand = try_skip(cur, k)\n",
        "                if cand:\n",
        "                    removed = edge(cur[k-1], cur[k])\n",
        "                    candidates.append((\"skip\", k, None, cand, removed))\n",
        "\n",
        "        if not candidates:\n",
        "            # No feasible local move found; stop early\n",
        "            break\n",
        "\n",
        "        # Pick best admissible candidate (tabu with aspiration)\n",
        "        pick_idx = None\n",
        "        pick_val = None\n",
        "        pick = None\n",
        "        for idx, (mtype, a, b, cand, removed_edge) in enumerate(candidates):\n",
        "            val = path_len(cand)\n",
        "            is_tabu = removed_edge in tabu\n",
        "            if (not is_tabu) or (val < best_val):  # aspiration\n",
        "                if pick_idx is None or val < pick_val:\n",
        "                    pick_idx, pick_val, pick = idx, val, (mtype, a, b, cand, removed_edge)\n",
        "\n",
        "        if pick is None:\n",
        "            # everything tabu and not improving best -> mild diversification\n",
        "            if tabu:\n",
        "                for _ in range(min(3, len(tabu))):\n",
        "                    tabu.pop(next(iter(tabu)))\n",
        "            continue\n",
        "\n",
        "        # Apply chosen move\n",
        "        mtype, a, b, cand, removed_edge = pick\n",
        "        cur = cand\n",
        "        cur_val = path_len(cur)\n",
        "        accepted += 1\n",
        "\n",
        "        # Update tabu with removed edge\n",
        "        tabu[removed_edge] = tabu_tenure\n",
        "\n",
        "        # Update global best\n",
        "        if cur_val < best_val:\n",
        "            best = cur[:]\n",
        "            best_val = cur_val\n",
        "\n",
        "    info = {\"iters\": it, \"accepted\": accepted, \"best_len\": best_val}\n",
        "    return best, info\n",
        "\n",
        "\n",
        "# helper function for tabu (also reused by GD)\n",
        "def repair_path_against_final(world: GridWorld, path: List[Coord]) -> List[Coord]:\n",
        "    # Make the flown path feasible under the world's *current* occupancy (including DynamicPositions)\n",
        "    if not path:\n",
        "        return []\n",
        "    repaired = [path[0]]\n",
        "    i = 0\n",
        "    while i < len(path) - 1:\n",
        "        # advance j over the longest run of free nodes\n",
        "        j = i + 1\n",
        "        while j < len(path) and world.IsFree(path[j]):\n",
        "            j += 1\n",
        "        j -= 1  # now path[i..j] are free (at least j=i)\n",
        "        # connect from current repaired tail to the farthest free waypoint\n",
        "        a = repaired[-1]\n",
        "        b = path[j]\n",
        "        leg = Astar(world, a, b)\n",
        "        if leg is None:\n",
        "            # if cannot connect directly, step one ahead to try again\n",
        "            if j == i:\n",
        "                i += 1\n",
        "            else:\n",
        "                i = j\n",
        "            continue\n",
        "        repaired.extend(leg[1:])\n",
        "        i = j + 1  # continue after the free stretch\n",
        "    return repaired\n",
        "\n",
        "\n",
        "# -------- Gradient Descent path improver (greedy local search) --------\n",
        "def gradient_descent_improve_path(world: GridWorld,\n",
        "                                  path: List[Coord],\n",
        "                                  time_limit: float = 0.5,\n",
        "                                  max_iters: int = 2000,\n",
        "                                  seed: int = 0) -> Tuple[List[Coord], Dict[str, int]]:\n",
        "\n",
        "    RNG = random.Random(seed)\n",
        "    if len(path) < 3:\n",
        "        return path[:], {\"iters\": 0, \"accepted\": 0, \"best_len\": max(0, len(path)-1)}\n",
        "\n",
        "    def path_len(pth: List[Coord]) -> int:\n",
        "        return max(0, len(pth) - 1)\n",
        "\n",
        "    def valid_consecutive(a: Coord, b: Coord) -> bool:\n",
        "        return abs(a[0]-b[0]) + abs(a[1]-b[1]) == 1\n",
        "\n",
        "    def feasible(pth: List[Coord]) -> bool:\n",
        "        for q in pth:\n",
        "            if not world.IsFree(q):\n",
        "                return False\n",
        "        for u, v in zip(pth, pth[1:]):\n",
        "            if not valid_consecutive(u, v):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def try_shortcut(cur_path: List[Coord], i: int, j: int) -> Optional[List[Coord]]:\n",
        "        if j <= i + 1:\n",
        "            return None\n",
        "        a, b = cur_path[i], cur_path[j]\n",
        "        new_leg = Astar(world, a, b)\n",
        "        if not new_leg or len(new_leg) < 2:\n",
        "            return None\n",
        "        cand = cur_path[:i+1] + new_leg[1:] + cur_path[j+1:]\n",
        "        return cand if feasible(cand) else None\n",
        "\n",
        "    def try_skip(cur_path: List[Coord], k: int) -> Optional[List[Coord]]:\n",
        "        if k <= 0 or k >= len(cur_path) - 1:\n",
        "            return None\n",
        "        a, b = cur_path[k-1], cur_path[k+1]\n",
        "        new_leg = Astar(world, a, b)\n",
        "        if not new_leg or len(new_leg) < 2:\n",
        "            return None\n",
        "        cand = cur_path[:k] + new_leg[1:] + cur_path[k+1:]\n",
        "        return cand if feasible(cand) else None\n",
        "\n",
        "    best = path[:]\n",
        "    best_val = path_len(best)\n",
        "    t0 = time.perf_counter()\n",
        "    accepted = 0\n",
        "    it = 0\n",
        "\n",
        "    while it < max_iters and (time.perf_counter() - t0) < time_limit:\n",
        "        it += 1\n",
        "        n = len(best)\n",
        "        if n < 3:\n",
        "            break\n",
        "\n",
        "        improved = False\n",
        "        current = best\n",
        "        current_val = best_val\n",
        "\n",
        "        # Generate a small random neighborhood of candidates (mixed moves)\n",
        "        candidates = []\n",
        "\n",
        "        # Shortcuts\n",
        "        if n >= 3:\n",
        "            for _ in range(16):\n",
        "                i = RNG.randrange(0, n - 2)\n",
        "                # local window or global pick\n",
        "                if RNG.random() < 0.6:\n",
        "                    j_min = i + 2\n",
        "                    j_max = min(n - 1, i + 2 + RNG.randrange(6))\n",
        "                    if j_min >= n:\n",
        "                        continue\n",
        "                    if j_max < j_min:\n",
        "                        j_max = j_min\n",
        "                    j = j_min if j_max == j_min else RNG.randrange(j_min, j_max + 1)\n",
        "                else:\n",
        "                    j_min = i + 2\n",
        "                    if j_min >= n:\n",
        "                        continue\n",
        "                    j = RNG.randrange(j_min, n)\n",
        "                cand = try_shortcut(current, i, j)\n",
        "                if cand:\n",
        "                    candidates.append(cand)\n",
        "\n",
        "        # Skips\n",
        "        if n > 3:\n",
        "            for _ in range(12):\n",
        "                k = RNG.randrange(1, n - 1)\n",
        "                cand = try_skip(current, k)\n",
        "                if cand:\n",
        "                    candidates.append(cand)\n",
        "\n",
        "        # Evaluate and accept the best strictly improving candidate\n",
        "        best_c = None\n",
        "        best_c_val = current_val\n",
        "        for c in candidates:\n",
        "            v = path_len(c)\n",
        "            if v < best_c_val:\n",
        "                best_c = c\n",
        "                best_c_val = v\n",
        "\n",
        "        if best_c is not None and best_c_val < best_val:\n",
        "            best = best_c\n",
        "            best_val = best_c_val\n",
        "            accepted += 1\n",
        "            improved = True\n",
        "\n",
        "        if not improved:\n",
        "            # No descent move found â€” stop\n",
        "            break\n",
        "\n",
        "    info = {\"iters\": it, \"accepted\": accepted, \"best_len\": best_val}\n",
        "    return best, info\n",
        "\n",
        "\n",
        "# Function to visualise dynamic and static environments for each algorithm\n",
        "def visualize_all(width=50, height=30, ObstacleRatio=0.18, DynamicObstacles=20,\n",
        "                  seed=7):\n",
        "    world_base = GridWorld(width=width, height=height,\n",
        "                           ObstacleRatio=ObstacleRatio,\n",
        "                           seed=seed,\n",
        "                           DynamicObstacles=DynamicObstacles,\n",
        "                           DynamicMove_Prob=0.25)\n",
        "\n",
        "# Algorithms\n",
        "\n",
        "    Algs = {\n",
        "        \"Astar_Coverage\": Astar_Coverage,\n",
        "        \"Random_Sweep\": RandomSweep,\n",
        "        \"Simulated_Annealing\": SimulatedAnnealing,\n",
        "        \"Ant_Colony\": AntColony,\n",
        "        \"Genetic_Algorithms\": GeneticAlgorithm,\n",
        "        \"PSO\": PSO,  # included\n",
        "    }\n",
        "\n",
        "    alg_names = list(Algs.keys())\n",
        "    n_algs = len(alg_names)\n",
        "\n",
        "    fig, axes = plt.subplots(n_algs, 2, figsize=(12, 3.4 * n_algs))\n",
        "    if n_algs == 1:\n",
        "        axes = np.array([axes])  # ensure 2D indexing\n",
        "\n",
        "    results_static: Dict[str, RunMetrics] = {}\n",
        "    results_dynamic: Dict[str, RunMetrics] = {}\n",
        "\n",
        "    # Hold per-algo optimizer summaries\n",
        "    opt_len_static_tabu: Dict[str, Tuple[int,int,int]] = {}   # (before, after, delta)\n",
        "    opt_len_dynamic_tabu: Dict[str, Tuple[int,int,int]] = {}\n",
        "    opt_len_static_gd: Dict[str, Tuple[int,int,int]] = {}\n",
        "    opt_len_dynamic_gd: Dict[str, Tuple[int,int,int]] = {}\n",
        "\n",
        "    for i, (name, fn) in enumerate(Algs.items()):\n",
        "\n",
        "        # ---- Static run ----\n",
        "        agent_s = Agent(start=(0, 0), BatteryCapacity=10_000, MoveCost=1)\n",
        "        world_s = GridWorld(width=world_base.width, height=world_base.height,\n",
        "                            ObstacleRatio=0.0, seed=seed,\n",
        "                            DynamicObstacles=0,\n",
        "                            DynamicMove_Prob=world_base.DynamicMove_Prob,\n",
        "                            Goal=world_base.Goal) # keep the SAME goal\n",
        "        world_s.grid = world_base.grid.copy()\n",
        "        world_s.DynamicPositions = []\n",
        "\n",
        "        met_s = fn(world_s, agent_s, seed=seed, dynamic=False)\n",
        "        results_static[name] = met_s\n",
        "\n",
        "        # --- Optimize (STATIC) ---\n",
        "        before_s = agent_s.path[:]  # keep original\n",
        "        # Tabu\n",
        "        opt_s_tabu, info_s_tabu = tabu_improve_path(world_s, before_s, time_limit=0.5, seed=seed)\n",
        "        before_len_s = len(before_s) - 1\n",
        "        after_len_s_tabu  = len(opt_s_tabu) - 1\n",
        "        opt_len_static_tabu[name] = (before_len_s, after_len_s_tabu, before_len_s - after_len_s_tabu)\n",
        "        # Gradient Descent\n",
        "        opt_s_gd, info_s_gd = gradient_descent_improve_path(world_s, before_s, time_limit=0.5, seed=seed)\n",
        "        after_len_s_gd = len(opt_s_gd) - 1\n",
        "        opt_len_static_gd[name] = (before_len_s, after_len_s_gd, before_len_s - after_len_s_gd)\n",
        "\n",
        "        ax_s = axes[i, 0]\n",
        "        img_s = np.where(world_s.grid == 1, 0.2, 1.0)\n",
        "        ax_s.imshow(img_s, cmap=\"gray\", origin=\"upper\",\n",
        "                    interpolation=\"nearest\",\n",
        "                    extent=(-0.5, world_s.width-0.5, world_s.height-0.5, -0.5))\n",
        "        ys = [p[0] for p in agent_s.path]\n",
        "        xs = [p[1] for p in agent_s.path]\n",
        "        ax_s.plot(xs, ys, linewidth=1.0, label=\"baseline\")\n",
        "        # overlay optimized path (Tabu dashed)\n",
        "        ys_tabu = [p[0] for p in opt_s_tabu]\n",
        "        xs_tabu = [p[1] for p in opt_s_tabu]\n",
        "        ax_s.plot(xs_tabu, ys_tabu, linewidth=1.0, linestyle=\"--\", label=\"tabu\")\n",
        "        # overlay gradient descent (red line)\n",
        "        ys_gd = [p[0] for p in opt_s_gd]\n",
        "        xs_gd = [p[1] for p in opt_s_gd]\n",
        "        ax_s.plot(xs_gd, ys_gd, linewidth=1.0, color=\"red\", label=\"grad-desc\")\n",
        "        ax_s.scatter([agent_s.path[0][1]], [agent_s.path[0][0]], marker=\"o\")\n",
        "        if world_s.Goal is not None:\n",
        "            ax_s.scatter([world_s.Goal[1]], [world_s.Goal[0]], marker=\"x\", s=80)\n",
        "        ax_s.set_title(f\"{name} â€” Static\\n\"\n",
        "                       f\"cover={met_s.CoveragePercentage:.1f}% | \"\n",
        "                       f\"path={met_s.PathLength}â†’{after_len_s_tabu} (tabu) / {after_len_s_gd} (gd)\")\n",
        "        ax_s.set_xticks([]); ax_s.set_yticks([])\n",
        "        ax_s.set_aspect('equal')\n",
        "        ax_s.legend(loc=\"lower right\", fontsize=8, frameon=False)\n",
        "\n",
        "        # ---- Dynamic run ----\n",
        "        agent_d = Agent(start=(0, 0), BatteryCapacity=10_000, MoveCost=1)\n",
        "        world_d = GridWorld(width=world_base.width, height=world_base.height,\n",
        "                            ObstacleRatio=0.0, seed=seed,\n",
        "                            DynamicObstacles=world_base.DynamicObstacles,\n",
        "                            DynamicMove_Prob=world_base.DynamicMove_Prob,\n",
        "                            Goal=world_base.Goal)  # <-- pass the SAME goal\n",
        "        world_d.grid = world_base.grid.copy()\n",
        "        world_d.DynamicPositions = list(world_base.DynamicPositions)\n",
        "\n",
        "        met_d = fn(world_d, agent_d, seed=seed, dynamic=True)\n",
        "        results_dynamic[name] = met_d\n",
        "\n",
        "        # --- Optimize (DYNAMIC) ---\n",
        "        before_d = agent_d.path[:]\n",
        "        # Option: repair the flown path *against the final world state* first\n",
        "        repaired_d = repair_path_against_final(world_d, before_d)\n",
        "        # Tabu\n",
        "        opt_d_tabu, info_d_tabu = tabu_improve_path(world_d, repaired_d, time_limit=0.5, seed=seed)\n",
        "        before_len_d = len(repaired_d) - 1\n",
        "        after_len_d_tabu  = len(opt_d_tabu) - 1\n",
        "        opt_len_dynamic_tabu[name] = (before_len_d, after_len_d_tabu, before_len_d - after_len_d_tabu)\n",
        "        # Gradient Descent\n",
        "        opt_d_gd, info_d_gd = gradient_descent_improve_path(world_d, repaired_d, time_limit=0.5, seed=seed)\n",
        "        after_len_d_gd = len(opt_d_gd) - 1\n",
        "        opt_len_dynamic_gd[name] = (before_len_d, after_len_d_gd, before_len_d - after_len_d_gd)\n",
        "\n",
        "        # Build a visualization grid where BOTH static and the FINAL dynamic\n",
        "        # obstacle positions are drawn as black cells (value=1)\n",
        "        vis_grid = world_d.grid.copy()\n",
        "        for (rr, cc) in world_d.DynamicPositions:\n",
        "            vis_grid[rr, cc] = 1  # paint dynamic obstacles black\n",
        "\n",
        "        ax_d = axes[i, 1]\n",
        "        img_d = np.where(vis_grid == 1, 0.2, 1.0)\n",
        "        ax_d.imshow(img_d, cmap=\"gray\", origin=\"upper\",\n",
        "                    interpolation=\"nearest\",\n",
        "                    extent=(-0.5, world_d.width-0.5, world_d.height-0.5, -0.5))\n",
        "\n",
        "        yd = [p[0] for p in agent_d.path]\n",
        "        xd = [p[1] for p in agent_d.path]\n",
        "        ax_d.plot(xd, yd, linewidth=1.0, label=\"baseline\")\n",
        "        # overlay optimized path (Tabu dashed)\n",
        "        yd_tabu = [p[0] for p in opt_d_tabu]\n",
        "        xd_tabu = [p[1] for p in opt_d_tabu]\n",
        "        ax_d.plot(xd_tabu, yd_tabu, linewidth=1.0, linestyle=\"--\", label=\"tabu\")\n",
        "        # overlay gradient descent (red line)\n",
        "        yd_gd = [p[0] for p in opt_d_gd]\n",
        "        xd_gd = [p[1] for p in opt_d_gd]\n",
        "        ax_d.plot(xd_gd, yd_gd, linewidth=1.0, color=\"red\", label=\"grad-desc\")\n",
        "\n",
        "        # start marker\n",
        "        ax_d.scatter([agent_d.path[0][1]], [agent_d.path[0][0]], marker=\"o\")\n",
        "\n",
        "        # GOAL marker\n",
        "        if hasattr(world_d, \"Goal\") and world_d.Goal is not None:\n",
        "            ax_d.scatter([world_d.Goal[1]], [world_d.Goal[0]],\n",
        "                         marker=\"x\", s=80, color=\"orange\", zorder=5)\n",
        "\n",
        "        ax_d.set_title(f\"{name} â€” Dynamic\\n\"\n",
        "                       f\"cover={met_d.CoveragePercentage:.1f}% | \"\n",
        "                       f\"path={met_d.PathLength}â†’{after_len_d_tabu} (tabu) / {after_len_d_gd} (gd)\")\n",
        "        ax_d.set_xticks([]); ax_d.set_yticks([])\n",
        "        ax_d.set_aspect('equal')\n",
        "        ax_d.legend(loc=\"lower right\", fontsize=8, frameon=False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary tables\n",
        "    print(\"\\n=== Static Results ===\")\n",
        "    for k, m in results_static.items():\n",
        "        print(f\"{k:22s} | Coverage={m.CoveragePercentage:6.2f}% | \"\n",
        "              f\"PathLength={m.PathLength:5d} | Overlap={m.OverlapCount:5d} | \"\n",
        "              f\"Time={m.ExecutionTime:6.3f}s | Energy={m.EnergyUsed:6d} | \"\n",
        "              f\"ReachedGoal={m.ReachedGoal} | \"\n",
        "              f\"TimeToGoal={('%.3fs' % m.TimeToGoal) if m.TimeToGoal is not None else 'None'}\")\n",
        "\n",
        "    print(\"\\n=== Dynamic Results ===\")\n",
        "    for k, m in results_dynamic.items():\n",
        "        print(f\"{k:22s} | Coverage={m.CoveragePercentage:6.2f}% | \"\n",
        "              f\"PathLength={m.PathLength:5d} | Overlap={m.OverlapCount:5d} | \"\n",
        "              f\"Time={m.ExecutionTime:6.3f}s | Energy={m.EnergyUsed:6d} | \"\n",
        "              f\"ReachedGoal={m.ReachedGoal} | \"\n",
        "              f\"TimeToGoal={('%.3fs' % m.TimeToGoal) if m.TimeToGoal is not None else 'None'}\")\n",
        "\n",
        "    # Optimizer summaries â€” Tabu\n",
        "    print(\"\\n=== Optimizer Summary (Tabu) â€” Static ===\")\n",
        "    for k in alg_names:\n",
        "        if k in opt_len_static_tabu:\n",
        "            b, a, d = opt_len_static_tabu[k]\n",
        "            red = (100.0 * d / b) if b > 0 else 0.0\n",
        "            print(f\"{k:22s} | Path Length Change {b:5d} â†’ {a:5d} | Change={d:4d} ({red:5.1f}%)\")\n",
        "\n",
        "    print(\"\\n=== Optimizer Summary (Tabu) â€” Dynamic ===\")\n",
        "    for k in alg_names:\n",
        "        if k in opt_len_dynamic_tabu:\n",
        "            b, a, d = opt_len_dynamic_tabu[k]\n",
        "            red = (100.0 * d / b) if b > 0 else 0.0\n",
        "            print(f\"{k:22s} | Path Length Change {b:5d} â†’ {a:5d} | Change={d:4d} ({red:5.1f}%)\")\n",
        "\n",
        "    # Optimizer summaries â€” Gradient Descent\n",
        "    print(\"\\n=== Optimizer Summary (Grad-Descent) â€” Static ===\")\n",
        "    for k in alg_names:\n",
        "        if k in opt_len_static_gd:\n",
        "            b, a, d = opt_len_static_gd[k]\n",
        "            red = (100.0 * d / b) if b > 0 else 0.0\n",
        "            print(f\"{k:22s} | Path Length Change {b:5d} â†’ {a:5d} | Change={d:4d} ({red:5.1f}%)\")\n",
        "\n",
        "    print(\"\\n=== Optimizer Summary (Grad-Descent) â€” Dynamic ===\")\n",
        "    for k in alg_names:\n",
        "        if k in opt_len_dynamic_gd:\n",
        "            b, a, d = opt_len_dynamic_gd[k]\n",
        "            red = (100.0 * d / b) if b > 0 else 0.0\n",
        "            print(f\"{k:22s} | Path Length Change {b:5d} â†’ {a:5d} | Change={d:4d} ({red:5.1f}%)\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    visualize_all(width=50, height=30, ObstacleRatio=0.18, DynamicObstacles=20, seed=7)"
      ]
    }
  ]
}